---
title: 探索实时数据大屏的关键技术
published: 2025-03-11
description: ''
image: ''
tags: [ CDC, Flink, 数据仓库, 数据湖, SSE, WebSockets ]
category: 学习笔记
draft: false
---

## 实时可视化数据大屏

```
[业务数据库] -> [CDC] -> [数据清洗、聚合、计算] -> [存储/传输]
```

### CDC

Change Data Capture（CDC，变更数据捕获）是一种实时或近实时追踪并捕获数据库数据变更的技术，主要用于将变更数据同步到下游系统（如数据仓库、缓存或微服务），以支持实时分析、数据集成和业务响应。

### CDC 的分类

CDC 主要分为基于查询的 CDC 和基于日志的 CDC

| 维度            | 基于查询的 CDC                             | 基于日志的 CDC                              |
|:--------------|:--------------------------------------|----------------------------------------|
| 概念            | 每次捕获变更发起 Select 查询进行全表扫描，过滤出查询之间变更的数据 | 读取数据存储系统的 log ，例如 MySQL 里面的 binlog持续监控 |
| 开源产品          | Sqoop, Kafka JDBC Source              | Canal, Maxwell, Debezium               |
| 执行模式          | Batch                                 | Streaming                              |
| 捕获所有数据的变化     | ❌                                     | ✅                                      |
| 低延迟，不增加数据库负载  | ❌                                     | ✅                                      |
| 不侵入业务         | ❌                                     | ✅                                      |
| 捕获删除事件和旧记录的状态 | ❌                                     | ✅                                      |
| 捕获旧记录的状态      | ❌                                     | ✅                                      |

### Binlog

Binlog（Binary Log，二进制日志）是 MySQL 数据库的核心日志文件，用于记录所有对数据库的结构变更和数据修改操作（如
INSERT、UPDATE、DELETE、CREATE TABLE 等），但不记录查询操作（如 SELECT）。它是 MySQL 实现数据持久化、主从复制和数据恢复的关键组件。

### Flink

Apache Flink 是一个开源的分布式流处理框架，专为高吞吐、低延迟、有状态的实时数据处理场景设计。它不仅能处理无界数据流（如实时日志、传感器数据），也能高效处理有界数据集（如批量文件），并统一了流处理和批处理的编程模型。

### 数据库、数据仓库、数据湖的对比

| 维度   | 数据库                    | 数据仓库                   | 数据湖                   |
|------|------------------------|------------------------|-----------------------|
| 数据类型 | 结构化数据（行/列）             | 结构化历史数据（已清洗）           | 原始数据（结构化/半结构化/非结构化）   |
| 数据模式 | 写入时定义（Schema-on-Write） | 写入时定义（Schema-on-Write） | 读取时定义（Schema-on-Read） |
| 处理目标 | 支持高频事务处理（OLTP）         | 支持分析查询（OLAP）           | 支持探索性分析与机器学习          |
| 存储成本 | 较高（需频繁优化存储结构）          | 高（需ETL处理）              | 低（支持原始格式存储）           |
| 数据治理 | 强（事务一致性保障）             | 强（数据清洗与标准化）            | 弱（需额外治理避免“数据沼泽”）      |
| 典型用户 | 业务操作人员                 | 数据分析师                  | 数据科学家、算法工程师           |

选择数据库：需要高频事务处理且数据结构固定的场景（如CRM系统）

选择数据仓库：需长期存储清洗后的历史数据并支持复杂分析（如BI报表）

选择数据湖：需存储多源异构数据并支持灵活分析（如AI模型训练）
三者并非互斥，现代企业常采用“湖仓一体”（Lakehouse）架构，结合数据湖的灵活性与数据仓库的治理能力，实现高效数据管理

### SSE

Server-Sent Events（SSE）是一种在客户端和服务端之间实现单向事件流的机制，允许服务端主动向客户端发送事件数据。在 SSE
中，可以使用自定义事件（Custom Events）来发送具有特定类型的事件数据。

### Server-Sent Events 与 WebSockets 的对比

| Server-Sent Events                  | WebSockets      |
|-------------------------------------|-----------------|
| 基于 HTTP 协议                          | 基于 TCP 协议       |
| 单工，只能服务端单向发送消息                      | 全双工，可以同时发送和接收消息 |
| 轻量级，使用简单                            | 相对复杂            |
| 内置断线重连和消息追踪的功能                      | 不在协议范围内，需手动实现   |
| 文本或使用 Base64 编码和 gzip 压缩的二进制消息      | 类型广泛            |
| 支持自定义事件类型                           | 不支持自定义事件类型      |
| 连接数 HTTP/1.1 6 个，HTTP/2 可协商（默认 100） | 连接数无限制          |
